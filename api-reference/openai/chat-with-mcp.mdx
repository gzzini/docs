---
title: "Chat with MCP"
api: "POST https://sac-waffle-v2.theo-110.workers.dev/openai/chat-with-mcp"
description: "Chat com Model Context Protocol para contexto din√¢mico"
---

## Descri√ß√£o

Model Context Protocol (MCP) permite adicionar contexto din√¢mico √†s conversas com IA. √ötil para incluir dados em tempo real, configura√ß√µes espec√≠ficas ou informa√ß√µes que mudam frequentemente.

## Headers

<ParamField header="Authorization" type="string" required>
  Bearer token JWT para autentica√ß√£o
</ParamField>

<ParamField header="Content-Type" type="string" required>
  `application/json`
</ParamField>

## Body Parameters

<ParamField body="prompt" type="string" required>
  Mensagem ou prompt para processar com contexto
</ParamField>

<ParamField body="systemPrompt" type="string">
  Instru√ß√µes do sistema
</ParamField>

<ParamField body="model" type="string" default="gpt-4o-mini">
  Modelo GPT a usar
</ParamField>

<ParamField body="contextProviders" type="array">
  Lista de provedores de contexto
  
  <Expandable title="Estrutura do Provider">
    <ParamField body="name" type="string" required>
      Nome identificador do provider
    </ParamField>
    
    <ParamField body="content" type="string" required>
      Conte√∫do do contexto
      
      **Exemplos:**
      - Dados do usu√°rio
      - Configura√ß√µes atuais
      - M√©tricas recentes
      - Hist√≥rico relevante
    </ParamField>
    
    <ParamField body="priority" type="number">
      Prioridade do contexto (maior = mais importante)
      
      **Valores:**
      - `0-10`: Baixa prioridade
      - `11-50`: M√©dia prioridade
      - `51-100`: Alta prioridade
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="maxContextLength" type="number" default="10000">
  Tamanho m√°ximo do contexto em caracteres
  
  **Considera√ß√µes:**
  - Contexto muito grande consome mais tokens
  - Prioridade determina o que incluir se exceder limite
</ParamField>

## Response

<ResponseField name="success" type="boolean" required>
  Status da opera√ß√£o
</ResponseField>

<ResponseField name="data" type="object">
  <Expandable title="Dados da resposta">
    <ResponseField name="content" type="string">
      Resposta gerada com contexto aplicado
    </ResponseField>
    
    <ResponseField name="usage" type="object">
      <Expandable title="Estat√≠sticas de uso">
        <ResponseField name="promptTokens" type="number">
          Tokens no prompt (incluindo contexto)
        </ResponseField>
        
        <ResponseField name="completionTokens" type="number">
          Tokens na resposta
        </ResponseField>
        
        <ResponseField name="totalTokens" type="number">
          Total consumido
        </ResponseField>
      </Expandable>
    </ResponseField>
    
    <ResponseField name="finishReason" type="string">
      Motivo do t√©rmino
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>

```bash Contexto de Usu√°rio
curl -X POST https://sac-waffle-v2.theo-110.workers.dev/openai/chat-with-mcp \
  -H "Authorization: Bearer seu_token_jwt" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Qual o status da minha conta?",
    "contextProviders": [
      {
        "name": "user_data",
        "content": "Usu√°rio: Jo√£o Silva\nAssinatura: The News\nStatus: Ativa\nPr√≥xima cobran√ßa: 15/02/2024\nStreak: 45 dias",
        "priority": 100
      }
    ]
  }'
```

```bash M√∫ltiplos Contextos
curl -X POST https://sac-waffle-v2.theo-110.workers.dev/openai/chat-with-mcp \
  -H "Authorization: Bearer seu_token_jwt" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Analise meu desempenho e sugira melhorias",
    "contextProviders": [
      {
        "name": "metrics",
        "content": "Taxa de abertura: 65%\nTaxa de cliques: 18%\nArtigos lidos: 127\n√öltimos 30 dias",
        "priority": 80
      },
      {
        "name": "preferences",
        "content": "Interesses: Tecnologia, Neg√≥cios\nHor√°rio preferido: 7h\nFormato: Resumo",
        "priority": 60
      },
      {
        "name": "history",
        "content": "Hist√≥rico: Leitor desde Jan/2023\nNewsletters assinadas: 3\nIndica√ß√µes: 5",
        "priority": 40
      }
    ],
    "maxContextLength": 15000
  }'
```

```bash Contexto de Sistema
curl -X POST https://sac-waffle-v2.theo-110.workers.dev/openai/chat-with-mcp \
  -H "Authorization: Bearer seu_token_jwt" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Gere um relat√≥rio de status",
    "systemPrompt": "Voc√™ √© um analista de sistemas. Gere relat√≥rios concisos e t√©cnicos.",
    "contextProviders": [
      {
        "name": "system_status",
        "content": "CPU: 45%\nMem√≥ria: 2.3GB/4GB\nRequests/min: 1250\nErros √∫ltima hora: 3\nUptime: 99.98%",
        "priority": 100
      },
      {
        "name": "alerts",
        "content": "Alertas ativos: 0\n√öltimo incidente: 3 dias atr√°s\nPr√≥xima manuten√ß√£o: 20/01/2024",
        "priority": 75
      }
    ]
  }'
```

</RequestExample>

<ResponseExample>

```json Resposta com Contexto de Usu√°rio
{
  "success": true,
  "data": {
    "content": "Ol√° Jo√£o! Sua conta est√° em perfeito estado:\n\n‚úÖ **Status:** Ativa\nüì∞ **Newsletter:** The News\nüí≥ **Pr√≥xima cobran√ßa:** 15 de fevereiro de 2024\nüî• **Streak atual:** 45 dias consecutivos - Parab√©ns!\n\nSua assinatura est√° funcionando perfeitamente e voc√™ tem mantido uma √≥tima sequ√™ncia de leitura. Continue assim para desbloquear mais recompensas!",
    "usage": {
      "promptTokens": 95,
      "completionTokens": 87,
      "totalTokens": 182
    },
    "finishReason": "stop"
  }
}
```

```json Resposta com M√∫ltiplos Contextos
{
  "success": true,
  "data": {
    "content": "## An√°lise de Desempenho\n\n### üéÜ Destaques\n- **Taxa de abertura de 65%** - Excepcional! 2.6x acima da m√©dia\n- **Taxa de cliques de 18%** - Engajamento muito alto\n- **127 artigos lidos** em 30 dias - M√©dia de 4+ por dia\n- **Leitor veterano** com 2 anos de hist√≥rico\n\n### üí° Sugest√µes de Melhoria\n\n1. **Maximize seu engajamento:**\n   - Com sua prefer√™ncia por Tecnologia, explore nossa se√ß√£o Tech Tuesday\n   - Considere assinar The Bizness para conte√∫do de neg√≥cios\n\n2. **Otimize sua experi√™ncia:**\n   - Seu hor√°rio das 7h √© perfeito para receber as newsletters\n   - Experimente o formato completo ocasionalmente para descobrir novos t√≥picos\n\n3. **Programa de indica√ß√µes:**\n   - Com 5 indica√ß√µes bem-sucedidas, voc√™ est√° pr√≥ximo do pr√≥ximo n√≠vel\n   - Mais 2 indica√ß√µes desbloqueiam benef√≠cios premium\n\nSeu perfil de leitura √© exemplar! Continue explorando e compartilhando.",
    "usage": {
      "promptTokens": 198,
      "completionTokens": 267,
      "totalTokens": 465
    },
    "finishReason": "stop"
  }
}
```

```json Resposta de Sistema
{
  "success": true,
  "data": {
    "content": "## RELAT√ìRIO DE STATUS DO SISTEMA\n**Timestamp:** 2024-01-15T14:30:00Z\n\n### RECURSOS\n- CPU: 45% (Normal)\n- RAM: 2.3GB/4GB (57.5% - √ìtimo)\n- Throughput: 1250 req/min (Dentro do esperado)\n\n### CONFIABILIDADE\n- Uptime: 99.98%\n- Erros (√∫ltima hora): 3 (0.004% das requisi√ß√µes)\n- √öltimo incidente: 72h atr√°s\n\n### STATUS OPERACIONAL\n‚úÖ Sistema est√°vel\n‚úÖ Sem alertas cr√≠ticos\n‚ÑπÔ∏è Manuten√ß√£o programada: 20/01/2024\n\n### RECOMENDA√á√ïES\n- Monitorar uso de RAM se ultrapassar 75%\n- Preparar rollback para manuten√ß√£o\n- Investigar os 3 erros para identificar padr√£o",
    "usage": {
      "promptTokens": 145,
      "completionTokens": 189,
      "totalTokens": 334
    },
    "finishReason": "stop"
  }
}
```

</ResponseExample>

## Casos de Uso do MCP

### üë§ Personaliza√ß√£o por Usu√°rio
```json
{
  "contextProviders": [
    {
      "name": "user_profile",
      "content": "Nome: Maria\nIdade: 28\nInteresses: Sa√∫de, Bem-estar",
      "priority": 100
    }
  ]
}
```

### üìä Dados em Tempo Real
```json
{
  "contextProviders": [
    {
      "name": "live_metrics",
      "content": "Visitantes online: 1,234\nVendas hoje: R$ 45,678\nTickets abertos: 23",
      "priority": 90
    }
  ]
}
```

### üìã Hist√≥rico de Conversa
```json
{
  "contextProviders": [
    {
      "name": "chat_history",
      "content": "Msg1: Usu√°rio perguntou sobre pre√ßos\nMsg2: Bot explicou planos\nMsg3: Usu√°rio pediu desconto",
      "priority": 80
    }
  ]
}
```

### ‚öôÔ∏è Configura√ß√µes Din√¢micas
```json
{
  "contextProviders": [
    {
      "name": "app_config",
      "content": "Modo: Produ√ß√£o\nFeatures: A/B Test ativo\nLimites: 100 req/min",
      "priority": 70
    }
  ]
}
```

## Prioriza√ß√£o de Contexto

Quando o contexto total excede `maxContextLength`, o sistema prioriza:

1. **Alta prioridade (51-100)**: Sempre inclu√≠do
2. **M√©dia prioridade (11-50)**: Inclu√≠do se houver espa√ßo
3. **Baixa prioridade (0-10)**: Inclu√≠do por √∫ltimo

## Melhores Pr√°ticas

### üéØ Seja Espec√≠fico
```json
{
  "name": "user_metrics",
  "content": "Opens: 45/50 (90%)\nClicks: 12/45 (26.7%)"
}
```

### üìè Mantenha Conciso
- Evite contextos muito longos
- Use formatos estruturados (JSON, listas)
- Remova informa√ß√µes redundantes

### ‚öñÔ∏è Balance Prioridades
- 100: Dados cr√≠ticos (identidade, seguran√ßa)
- 75: Informa√ß√µes principais
- 50: Contexto √∫til
- 25: Informa√ß√µes complementares

### üîÑ Atualize Dinamicamente
```javascript
// Exemplo de contexto din√¢mico
const context = {
  name: "real_time_data",
  content: JSON.stringify({
    timestamp: Date.now(),
    activeUsers: getActiveUsers(),
    systemLoad: getSystemLoad()
  }),
  priority: 90
};
```

## Limita√ß√µes

1. **Tamanho m√°ximo**: 10000 caracteres por padr√£o
2. **Consumo de tokens**: Contexto conta para o limite
3. **Lat√™ncia**: Contextos grandes aumentam tempo de resposta
4. **Custo**: Mais contexto = mais tokens = maior custo